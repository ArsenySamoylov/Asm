# Введение
Это директория посвящена практическому изучению оптимизации производительности программы. Эта задача будет изучаться на примере структуры данных - хеш-таблицы. Данная работа состоит из двух частей. Первая нацелена на то, чтобы познакомиться со структурой данных - хеш-таблицей, и рассмотреть возможные оптимизации на абстрактном уровне алгоритма, на примере разных хеш-функций. Вторая часть направлена на поиск "узких мест" уже существующего алгоритма и их устранение.


# Цель работы
Основная цель этой работы - это научится правильно анализировать абстрактную модель программы и оптимизировать её реализацию, написанную на языке Си.

# Задачи
На примере структуры данных, хеш-таблицы, сделать два уровня исследований.
На первом уровне анализируется абстрактная модель работы хеш-таблицы, на втором уровне оптимизируется реализация данной модели.

# Гипотеза
Чтобы добиться хорошего результата работы программы нужно тщательно исследовать и абстрактную модель, и её реализацию.

# <a name="section-experimental-setup"></a> Экспериментальная установка
Ноутбук фирмы "Acer" на процессоре "Intel(R) Core(TM) i5-10300H CPU @ 2.50GHz" и операционной системой "GNU/Linux 22.04.1-Ubuntu x86_64".

# Теоретическое введение
Для исследований, как уже было сказано выше, была выбрана одна из стандартных и широко использующихся структур данных: хеш-таблица.
Пару слов, о  том что такое хеш-таблица:

**Хеш-таблица** — это структура данных, в которой все элементы хранятся в виде пары ключ-значение, где:

*ключ* — уникальное число, которое используется для индексации значений;

*значение* (или элемент) — данные, которые с этим ключом связаны. 

*Хеш-функция* — функция сопоставляющее каждому значению соответсвующим ему ключ.

Каждое *значение* не обязательно должно иметь уникальный *ключ*. В ситуации, когда несколько *значений* имеют одинаковые *кдючи* называют *коллизиями*. Хеш-таблицы делятся на разные типы, по тому как они борятся с *коллизиями*. Два основные метода это:
1. метод цепочек
2. метод открытой адресации

В данной работе мы будем использовать метод цепочек. 

Суть этого метода проста: если хеш-функция выделяет один индекс сразу двум элементам, то храниться они будут в одном и том же индексе, но уже с помощью двусвязного списка (далее вместо *индекса* мы будем использовать термин *контейнер*,  имея в виду двусвязный список *значений* с одинаковыми *ключами*).

Визуализация хеш-таблицы методом цепочек, взятом из [данного источника](https://codechick.io/tutorials/dsa/dsa-hash-table_exmp.png)[^1]. (там же можно подробнее узнать о том, как работает хеш-таблица)

![hash table visualization](resources/hashatable_exmp.png)


# Ход работы

## **Первая часть**
Перед тем как начать анализировать абстрактную модель хеш-таблицы, нужно сначала понять, почему для работы была выбрана именно данная структура данных.

### **Почему хеш-таблица?**
Хеш-таблица была выбрана неспроста. Это достаточно популярная структура, которая находит широкое применение во всех областях программирования. Так же, хорошо подобранная модель хеш-таблицы имеет множество преимуществ в качестве способа хранения данных.

Однако эффективность хеш-таблицы напрямую зависит от её заселенности (среднего количесва элементов в контейнерах) и равномерности заполнения. 
Хеш-таблицы считается хорошей, когда в среднем в каждом контейнере ~ 1.5-2 элемента.

Равномерность заполнения хеш-таблицы возьмем за основной параметр для исследований в первой части.

### **Постановка цели**
Теперь, когда мы определили параметры по которым будем оценивать эффективность нашей модели хеш-таблицы, можно сформулировать цель для исследования в первой части.

**Наша цель**: добится макимально возможного равномерного распределения по контейнерам.

### **Анализ модели и выбор её параметров для исследований**
Так как это исследовательская работа, то мы можем позволить себе некоторые изменения модели хеш-таблицы.

Для хорошей репрезентативности мы будем симулировать ситуацию, когда элементов настолько много, что в каждом контейнере гораздо больше двух элементов. Данная ситуация позволять более отчетливо выявить неравномерность распределения элементов.
Для эксперимента будем добиваться условий, когда в каждом контейнере примерно 20-25 элементов. Для достижения этих параметров будем использовать два метода:
1. большое количество элементов для хранение в структуре данных
2. ограничения количества контейнеров
 
Для выполнения работы в качесве элементов выберем английские слова. В качестве базы данных возьмем произведение Вильяма Шекспира "Гамлет". В хеш-таблице будут хранится только уникальные слова, которых в данном тексте  ~ 5178. Таким образом, наша цель - добится, чтобы в среднем в контейнере было 20-25 элементов. Для этого понадобится примерно около 230 контейнеров. 

Для колличесва контейнеров лучше всего подбирать *простые числа*. Так как, при существовании зависимости между данными, хеш-функции могут выдавать значения с определенными законмерностями, и нахождения остатка от деления на непростое число может быть хуже распределенным, чем при делении на простое. (Подробнее об это можно прочитать например [по этой ссылке](https://medium.com/swlh/why-should-the-length-of-your-hash-table-be-a-prime-number-760ec65a75d1)[^2].)

Ближайшее простое число к 230, это **227**. Именно его возьмем за наше количество контейнеров.

### **Хеш-функции**
Теперь, когда мы определились с моделью и параметрами нашей хеш-таблицы, перейдем к выполнению цели: *достижение максимально возможного равномерного распределения*.

Хеш-функция - это один главных факторов, напрямую определяющий распределение элементов по контейнерам. Именно хеш-функция отвечает, в каком контейнере будем хранится элемент. 
Поэтому первая часть работы будет посвящена исследованию различных хеш-функций.

<hr>

#### **Замечание**
Важно отметить, что на распределение хеш-функции, как уже было отмечено выше, так же влияет количество контейнеров. Однако исследование этого вопроса оставим вне кргуга нашей работы. Поэтому в течение всей работы количесво контейнеров будет постоянным и равным *227*.
<hr>

Выберем восемь различных функций, которые каждому слову сопоставляют:
1. всегда еденицу
2. ASCII код первого символа
3. длину слова
4. сумму ASCII кодов всех символов

Так же используем еще четыре функции, в алгоритм работы которых, мы не будем углубляться в контексте данной работы:
5. rol
6. ror
7. djb2
8. crc32

### **Измерения**

Теперь посмотрим на распределение элементов по контейнерам для разных функций.

<details>
<summary> Таблица распределения по первым 10 контейнерам для всех хеш-функций </summary>

##### таблица 1. Распределение по первым 10 контейнерам для всех хеш-функций
Название функции | 1|   2    | 3  | 4   | 5     | 6     | 7     | 8     | 9     |10
---------------|----|--------|----|-----|-------|-------|-------|-------|-------|------
hash1_always_1 | 0  |	5183 | 0  |	0	| 0	    | 0 	| 0	    | 0	    | 0	    | 0
hash2_ascii    | 0  |	0	 | 0  |	0	| 0	    | 0 	| 0	    | 0	    | 0	    | 0
hash3_strlen   | 0  |	13	 | 74 |	277	| 787	| 964	| 921	| 820	|577	|364
hash4_hash_sum | 14 |	5	 | 12 |	9	| 8     | 6	    | 2     |	1	| 4	    | 3
hash5_rol 	   | 27 |    21	 | 18 |	23	|22	    |24	    | 16	| 17	| 27	| 23
hash6_ror 	   | 20 |	14	 | 24 |	25	| 27	| 26	| 31	| 22	| 25	| 22
hash7_djb2 	   | 27 |	22	 | 28 |	27	| 14	| 23	| 26	| 25	| 13	| 20
hash8_crc32    | 22 |	20	 | 28 |	17	| 18	| 23	| 15	| 22	| 17	| 28

</details>

<br /> 
Невооруженным глазом видно, что первые три функции имеют плохое распределение:

1. первая функция использует только один контейнер из *227*
2. вторая функция ограничена, так ASCII  букв английского алфавита код может принимать только 52 значения (26 букв и два регистра). Следовательно используется максимум 52 контейнера из *227*
3. третья функция возвращет длину слова. В данном тексте нет ни одного слова, длина которого превоходила бы 20 символов, следовательно более 200 контейнеров остаются пустыми

По этомоу отбросим их из дальнейшего рассмотрения.

<br /> 
Для анализа оставшихся функций, посторим гистограмы, показывающее распределение по контейнерам.

<details>
<summary> Графики распределение функций </summary>

На всех графиком красная линия - это среднее значение количесва элементов в контейнере.

##### гистограмма 1. Распределение функции hash4_hash_sum.
![Распределение функции hash4_hash_sum.](resources/hash4_hash_sum.png)

##### гистограмма 2. Распределение функции hash5_rol.
![Распределение функции hash5_rol.](resources/hash5_rol.png)

##### гистограмма 3. Распределение функции hash6_ror.
![Распределение функции hash6_ror.](resources/hash6_ror.png)

##### гистограмма 4. Распределение функции hash7_dbj2.
![Распределение функции hash4_hash_sum.](resources/hash7_djb2.png)
z
##### гистограмма 5. Распределение функции hash8_crc32.
![Распределение функции hash8_crc32.](resources/hash8_crc32.png)

</details>

Из данных гистограм, видно, что: 

`hash4_hash_sum` - имеет волно образно распределение, с достаточно высокими гребными, из-за чего элементы плохо распределены

`hash6_ror` - сначала имеет достаточно глубокою "яму", после которой много контейнеров заполнено значительно выше среднего значения.

Поэтому отбросим их, и сфокусируем внимание на оставшихся трех функциях:
1. `hash5_rol`
2. `hash7_dbj2`
3. `hash8_crc32`

По гистограмам сложно определить функцию с лучшим распределнием, поэтому расчитаем дисперсию для этих трех функций.

##### **таблица 2**. Дисперсия функий в условных единицах
| Название функции | Дисперсия, у.е.
|------------------|-------------------------------
| `hash5_rol` 	   | 25.18
| `hash7_djb2` 	   | 25.72
| `hash8_crc32`    | 23.99

Из данной таблицы видно, что лучшими показателем (наименьшей дисперсией) обладает функция `hash8_crc32`.

Именно эту функцию и выберем для нашей хеш-таблицы.

<hr>

### *Замечение*
Интересно посмотреть, как будет меняться дисперсия выше отобранных функций, если немног поменять количество контейнеров.

##### **таблица 3**. Дисперсия функий в условных единицах, при разном количестве контейнеров
| Название Функции | 223 контейнеров | 211 контейнеров |229 контейнеров 
|------------------|-----------------|-----------------|-------------
| `hash5_rol` 	   | 24.36           | 24.94           | `20.34`
| `hash7_djb2` 	   | `21.14`         | `22.33`         | 24.65
| `hash8_crc32`    | 28.70           | 25.18           | 20.89

Из этих данных видно, что значения дисперсии флуктуируют, и при таких размерах `hash8_crc32` не является лучшей функцией. 
<hr>

### **Выводы из первой части**
Понимая, как работает модель хеш-таблицы, мы выявили, что главной характеристикой хеш-таблицы является равномерность распределения, которая на прямую зависит от типа данных и хеширующей функции.
 
Проанализировав наше установку, мы смогли найти оптимальную хеш функцию, которая позволят достичь достачно равномерного распределения элементов.

## **Вторая часть**

### **Что делаем теперь?**
В первой части мы анализировали хеш-таблицу как абстрактную модель, не углубляясь в детали ее реализации. Теперь же займемся исследованием конкретной модели, реализованной для этой лабораторной работы.

Первое с чем нужно определится - это какой аспект программы мы будем исследовать. Например, это может быть загрузка таблицы из памяти. Однако в основном хеш-таблица структура данных, которая долго живет в программе. И соответсвеноо загрузка и удаление таблицы занимают заметное меньшее время по сравнению с временем жизни структуры. Поэтому оставим эти оптимизации вне круга нашей работы.

Вернемся к модели хеш-таблицы из первой части.
Из-за большего количества коллизий поиск элемента становится затруднительным, так как высчитать хеш элемента уже недостаточно. Поэтому сфокусируемся на задаче поиска элемента.   

### **Анализ производительности**
Создадим тестовую ситуацию, когда мы ищем большое множество в хеш-таблице. Для поиска будем использовать слова из сказки Льюиса Кэрролла "Алиса в Стране чудес". 

Так как время, затрачиваемое на один проход по поиску всех слов мало, то следует измерять время работы нескольких вызовов одной и той же функции поиска. Это позволит понизить погрешности измерений и получить более достоверный результат для сравнения.

Для просмотра затрачиваемых программой ресурсов будем использовать профайлер [Callgrind](https://habr.com/ru/articles/167837/)[^3], являющийся встроенным инструментом в утилиту [Vallgrind](https://valgrind.org/)[^4].

Теперь посмотрим на статистику нашей программы (цифрами обозначается общее количесво машинных инструкций, выполненых в функции):

##### приложение 1. Граф вызовов функций. 
![callgring statisics without optimizations](resources/profiling_no_optimizations.png)

Из данного графа видно, что больше половины машинных команд уходит на вычисление хеша и сравнение строк. Поэтому начнем оптимизации именно с этих функций.

### **Выбор типа данных**
Но перед началом оптимизации функций нужно решить каким типом данных будут реализованы даные. Важно начать именно с этого, так как это краеугольный камень в реализации программы.

От типа данных зависит реализация основных функций, таких как: высчитывание хеша элемента, поиск и сравнение элементов. Поэтому начнем оптимизацию именно с этого.

В данной работе элементы - это слова. В начальной реализации базовым типом был массив символов. 
Однако слова удобно представлять в виде векторов, так как это позволяет работать со словом целиком, а не с каждым символом поотдельности.  

Из [предыдущей работы](https://github.com/ArsenySamoylov/Asm/tree/master/SIMD) по изучению SIMD-инструкций мы знаем о существований специальных интринсиков для работы с 256 битными векторами. Такой вектор позволит хранить слово длиной до 32 букв, что более чем достаточно для наших исходных данных.
   
Однако у такого способа есть один большой недостаток:
- это повышенный расхода памяти. Каждое слово становится 256 битным вектором вне зависимости от его длины.

Этот недостаток можно решить, если вместе с каждым словом хранить его длину и в дальнейшем перейти к неравномерному хранению данных. 

??? Так как устранение этого недостака непринципиально в контексте данной работы (хранения длины слова и переход к неравномерному хранению данных, существенно уменьшит потребление памяти и не сильно повлият на производительность, но займет дополнительное время для имплементации в нашей моделе), то его применение будет оставлено вне работы.??? 

Теперь, когда мы определились с типом, которым будут представлены наши данные, перейдем к оптимзации функций рачсета хеша и сравнения элементов

### **Оптимизация функций**

Начнем оптимизации с самой ресурсозатратной функции - `hash8_crc32_not_optimized`. 
Алгоритм хеширования crc32 достаточно распростаранен и имеет встроенную аппаратную поддержку на множестве систем, не исключая [нашу экспериментальную установку](#section-experimental-setup).
Есть три подхода к написанию оптимизированной функции, расчитывающей хеш:
1. написать её на ассемблере
2. написать её на инлайн ассемблере (или ассемблерная вставка
3. напистаь её на интрисиках
   
Реализуем все три вида и проанализируем их.

#### **таблица 4.**
Название функции         | Количество инструкций, миллионов
-------------------------|---------------------------------
`hash8_crc32_assembler`  | `191`
`hash8_crc32_inline_as`  | 273 
`hash8_crc32_intrinsics` | 383

Из таблица видно, что ассемблерная реализация показала лучший результат.
Однако у ассемблерной вставки есть преимущество, компилятор может подставить ее напрямую в функцию поиска элемента, тем самым уменьшая количесво инструкций.

Так как вызов функции заменяется на подстановку кода, то с помощью Callgrind`a нельзя оценить затраты на такую функцию.

Для оценки напишем небольшую вспомогательную программа, которая будет в цикле расчитывать хеш для элементов из "Алисы в Стране чудес". 

Используя опцию компилятора `save-temps` убедимся, что компилятор действительно подставляет код из ассемблерной вставки:

Фрагмент исходной строчки
```
volatile index_ temp = hash8_crc32_assembler (test_data_array++);
```

Ассемблерный код функции написанной на ассемблере
```
.LVL10:
	.loc 1 98 54 view .LVU42
	call	hash8_crc32_assembler@PLT
```

Фассемблерный код для функции написанной на инлайн-ассемлере
```
.LVL1:
#APP
# 28 "./include/HashFunctions.hpp" 1
	
         .intel_syntax noprefix
          cmp %rax, 0x0
          je 1f
          
          xor %rdi, %rdi

          crc32 %rdi, qword ptr [%rax + 0x00 ]
          crc32 %rdi, qword ptr [%rax + 0x08 ]
          crc32 %rdi, qword ptr [%rax + 0x10 ]
          crc32 %rdi, qword ptr [%rax + 0x18 ]
        1:
       
        .att_syntax prefix
```
Отсюда видно, что копилятор действительно подставил код из ассемблерной вставки.

Теперь замерим время для функции написанной на инлайн-ассемблере и на обычно ассемблере.

#### **таблица 5.** Сравнение инлайн-ассемблера 
Функция                  | Время для *10000* итераций, секунды
-------------------------|---------------------------------
`hash8_crc32_assembler`  | 2.31 
`hash8_crc32_inline_as`  | 9.17 

Из таблицы видно, что функция, написанная на инлайн-ассемблере, заметно быстрее функции, написанной на простом ассемблере. 

Из этого можно сделать вывод, что при оптимизации лучше использовать ассемблерную вставку вместо написании функции на чистом ассемблере.

Поэтому остановимся на выборе функции написанной на инлайн-ассемблере.

Однако, нужно сделать замечание, для достижения такого результата, пришлось изменить исходный код, заменив указатель на функцию, на явыный вызов (иначе компилятор бы не смог выполнить подстановку).

Код до сравнения:
```
volatile index_ temp = (*hash_func_ptr) (test_data_array++);
```
Код вовремя сравнения:
```
volatile index_ temp = hash8_crc32_inline_as (test_data_array++);
```

Замерим, на сколько изменилось время поиска:

#### **таблица 6.**
Версия программы                | Время поиска, секунды
--------------------------------|---------------------------------
без оптимизаций                 |
версия с первой оптимизацией    | 



# Заключение
Все за*бись!

## Источники
[^1]: https://codechick.io/tutorials/dsa/dsa-hash-table
[^2]: https://medium.com/swlh/why-should-the-length-of-your-hash-table-be-a-prime-number-760ec65a75d1
[^3]: https://habr.com/ru/articles/167837/
[^4]: https://valgrind.org/